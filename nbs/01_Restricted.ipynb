{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed9bae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp restricted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45cb2a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e51f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from os import path, makedirs\n",
    "from copy import copy\n",
    "from math import factorial\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.random import rand as rnd\n",
    "from numpy import newaxis as nax\n",
    "from numpy import real_if_close as ric\n",
    "from scipy.optimize import brentq\n",
    "from sys import exit as se, argv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf4b134",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T13:42:38.982206Z",
     "start_time": "2022-03-08T13:42:38.961295Z"
    }
   },
   "source": [
    "# Restricted Hartree-Fock\n",
    "> API details. author: Lorenzo Cardarelli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57e53fd",
   "metadata": {},
   "source": [
    "## Mean-field Hamiltonian in k-space, 8-sites cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf01d40",
   "metadata": {},
   "source": [
    "This part of the library focuses on solving the system Hamiltonian\n",
    "\\begin{aligned}\n",
    "H = &-t_0\\sum_{<ij>}(c_i^\\dagger c_j + H.c.)+J^A_x\\sum_{i\\in A}(c_{i}^\\dagger c_{i+x} + H.c.) \n",
    "        +J^A_y\\sum_{i\\in A}(c_{i}^\\dagger c_{i+y} + H.c.)\\\\\n",
    "        &+J^B_x\\sum_{i\\in B}(c_{i}^\\dagger c_{i+x} + H.c.) +J^B_y\\sum_{i\\in B}(c_{i}^\\dagger c_{i+y} + H.c.) \n",
    "        +V_1\\sum_{<ij>}n_in_j+V_2\\sum_{<<ij>>}n_in_j\\\\\n",
    "        &+V_3\\sum_{<ij>_3}n_in_j+V_4\\sum_{<ij>_4}n_in_j\n",
    "\\end{aligned}   \n",
    "self-consistently with a restricted Hartree fock ansatz on the 8-site unit cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aa91028",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#export\n",
    "class checkerboard_eight_sites():\n",
    "    def __init__(self):\n",
    "        # 8-sites checkerboard attributes\n",
    "        self.classtag = 'checkerboard_eight_sites'\n",
    "        self.site_coos = np.array([[0,2,1,3,0,2,1,3],[0,0,1,1,2,2,3,3]]).T   \n",
    "        self.cellBravaisvecs = np.array([[4.,0.], [0.,4.]])\n",
    "        self.pairs_negative_J_flux = ([0,1,2,6,4,5,3,7],[4,5,3,7,0,1,2,6])\n",
    "        self.nsites = 8 # Number of sites in the unit cell.\n",
    "        self.ncs = 5 # Min number of neighboring cells (+1) needed for lattice tiling.\n",
    "        self.xiQAH_loop_mask = (np.array([1,2,5,3]), np.array([2,5,3,1])) # Coordinates of the sites on a square plaquette of the unit cell over which the topological order parameter is calculated.\n",
    "        # Checkerboard attributes and methods\n",
    "        self.set_lattice_specs()\n",
    "        # Set that lattice is 2-dimensional\n",
    "        self.d = 2\n",
    "        self.get_kgrid()\n",
    "        self.get_eikd()\n",
    "        return\n",
    "\n",
    "    def get_hopping_matrix(self):\n",
    "        hop = np.zeros([self.nV,5,self.nBands,self.nBands])\n",
    "        hop[1] = -self.t*self.distance_mask_hc[1]\n",
    "        m = np.ones([self.nsites,self.nsites],dtype=int)\n",
    "        m[self.pairs_negative_J_flux] = -1\n",
    "        sign_mask = np.ones([5,self.nsites,self.nsites])*m\n",
    "        hop[2] = self.J*self.distance_mask_hc[2]*sign_mask\n",
    "        for _ in range(3,self.nV):\n",
    "            hop[_] = hop[0]*0\n",
    "        self.bare_hopping_hc = hop\n",
    "        return\n",
    "\n",
    "    def init_EkUk(self):\n",
    "        shape = list(self.kgridsize)\n",
    "        n = self.nBands\n",
    "        self.Ek = np.zeros(shape + [n], dtype=float)\n",
    "        self.Uk = np.zeros(shape + [n, n], dtype=complex)\n",
    "        return\n",
    "\n",
    "    def get_kuv(self):\n",
    "        # k-lattice unit vectors\n",
    "        k1 = 2*np.pi*np.array([1.,0.])\n",
    "        k2 = 2*np.pi*np.array([0.,1.])\n",
    "        return k1, k2\n",
    "\n",
    "    def set_lattice_specs(self):\n",
    "        e1 = [1,-1]; e2 = [1,1]; # Bravais vectors\n",
    "        self.square_distances = [0,2,4,8,10,18][:self.nV] # square of the distances between lattice sites\n",
    "        self.r_prim_vecs = np.array([e1,e2])\n",
    "        self.k_prim_vecs = np.pi * self.r_prim_vecs / np.linalg.norm(e1)**2\n",
    "        self.FTvecs = self.r_prim_vecs\n",
    "        self.nBands = self.site_coos.shape[0]\n",
    "        self.band_filling = np.rint(self.nBands/2).astype(int) # half-filling\n",
    "        return\n",
    "\n",
    "    def get_interaction_matrix(self):\n",
    "        self.interactions_hc = np.zeros([self.nV,5,self.nBands,self.nBands])\n",
    "        for _ in range(self.nV):\n",
    "            self.interactions_hc[_] = self.Vsarray[_]*self.distance_mask_hc[_]\n",
    "        returncla\n",
    "\n",
    "    def get_Hoffdiag(self):\n",
    "        bx, by = self.BZindices\n",
    "        H = self.bare_hopping_hc*self.eikdhc[:,bx,by]\n",
    "        H -= self.interactions_hc*self.eikdhc[:,bx,by]*np.conj(self.corrhc[:])\n",
    "        H = np.sum(H,axis=(0,1))\n",
    "        return H\n",
    "\n",
    "    def get_Hdiag(self):\n",
    "        nmat = np.ones([self.nBands,self.nBands])*np.diag(self.corrhc[0,0,:,:])\n",
    "        mfs = np.sum( nmat*self.distance_weight_hc_flat, axis=2)\n",
    "        H = np.diag( np.sum(self.Vsarray[:,nax]*mfs, axis=0))\n",
    "        return H\n",
    "\n",
    "    def get_Hc(self, d=0):\n",
    "        d = np.diag( ric(self.corr[0,0,:,:]) )\n",
    "        nmat = np.ones([self.nBands,self.nBands]) * d\n",
    "        Hc = 0\n",
    "        Hc = -np.sum( self.Vsarray[:,nax,nax]*self.distance_weight_flat*nmat*nmat.T )\n",
    "        Hc += np.sum( self.Vsarray[:,nax,nax,nax]*self.cosq )\n",
    "        Hc = ric(Hc)\n",
    "        return Hc\n",
    "\n",
    "    def get_Hamiltonian(self):\n",
    "        self.H = self.get_Hoffdiag()\n",
    "        self.H += self.get_Hdiag()\n",
    "        return\n",
    "\n",
    "    def init_outputdata(self):\n",
    "        self.basic_params = ['rho%d' %_ for _ in range(self.nV)] + ['xiQAH']\n",
    "        MFp = {}\n",
    "        for key in self.basic_params:\n",
    "            MFp[key] = rnd()\n",
    "        self.outputdata = copy(MFp)\n",
    "        self.oldoutputdata = copy(MFp)\n",
    "        self.osc_counter = 0\n",
    "        return\n",
    "\n",
    "    def init_rnd_corr(self,verbose=True):\n",
    "        # corrhc : [neighood,cp,nB,nB]\n",
    "        def foo(k=0):\n",
    "            return rnd( self.nV-k, 5, self.nBands, self.nBands ).astype(np.complex128)\n",
    "        corrhc = 0*foo()\n",
    "        if '-corrm' in argv:\n",
    "            if self.corrm == 'real':\n",
    "                corrhc[1:] = foo(1)\n",
    "                self.permaprt('Correlation matrix initialized to random real values.',verbose=verbose)\n",
    "            elif self.corrm == 'comp':\n",
    "                corrhc[1:] = foo(1) + 1.j*foo(1)\n",
    "                self.permaprt('Correlation matrix initialized to random complex values.',verbose=verbose)\n",
    "            else:\n",
    "                se('To initialize the correlation matrix to real (complex) values, please use \"-corrm real\" (comp).')\n",
    "        else:\n",
    "            corrhc[1:] = foo(1) + 1.j*foo(1)\n",
    "            self.permaprt('Correlation matrix initialized to random complex values.',verbose=verbose)\n",
    "        d = np.random.rand(self.nBands)\n",
    "        d *= self.band_filling/np.linalg.norm(d,1) \n",
    "        np.fill_diagonal(corrhc[0,0], d)\n",
    "        self.corrhc = corrhc*self.distance_mask_hc\n",
    "        self.get_corr_cosq()\n",
    "        return\n",
    "\n",
    "    # ********** Correlations, data\n",
    "\n",
    "    def get_xiQAH(self):\n",
    "        xiQAH = np.abs(np.sum(np.imag(self.corrhc[1,0][self.xiQAH_loop_mask])))/4\n",
    "        return xiQAH\n",
    "\n",
    "    def get_rho(self, d):\n",
    "        n = ric(np.diag(self.corrhc[0,0]))\n",
    "        w = np.where( self.distance_mask[d,0] )\n",
    "        ni = n[w[0]]\n",
    "        nj = n[w[1]]\n",
    "        rho = np.prod(np.abs(ni-nj))\n",
    "        return rho\n",
    "\n",
    "    def get_outputdata(self):\n",
    "        self.outputdata['xiQAH'] = self.get_xiQAH()\n",
    "        for d in range(0, self.nV):\n",
    "            self.outputdata['rho%d'%d] = self.get_rho(d)\n",
    "        return\n",
    "\n",
    "    def sort(self, w, v):\n",
    "        lowfirst = np.argsort(w)\n",
    "        w = w[lowfirst]\n",
    "        v = v[:, lowfirst]\n",
    "        return w,v\n",
    "\n",
    "    def check_convergence(self,verbose=False):\n",
    "        self.oldcorr_grad_max = copy(self.corr_grad_max)\n",
    "        grad = self.oldcorrhc - self.corrhc\n",
    "        agrad = np.abs(grad)\n",
    "        amax = np.max(agrad)\n",
    "        self.corr_grad_max = grad[np.where(agrad == amax)][0]\n",
    "        self.delta_FE = abs(self.oldFE - self.FE)\n",
    "        cgd_norm = np.linalg.norm(self.corr_grad_max)\n",
    "        if verbose:\n",
    "            self.permaprt('self.FE : %.16f, correlation gradient norm : %.16f' %(self.FE, cgd_norm))\n",
    "        # If the max gradient is above 1.E-4 for more than 100 iters, call it oscillation.\n",
    "        if cgd_norm >= self.oscillation_threshold:\n",
    "            self.large_gradient_counter += 1\n",
    "            if self.large_gradient_counter == self.consecutive_oscillations:\n",
    "                self.terminate = True\n",
    "        else:\n",
    "            self.large_gradient_counter += 1\n",
    "        # Convergence if both cgd_norm and delta_FE below threshold or if one mean-field operator is self.convergence_thresh_mfops times larger than all others.\n",
    "        if (max(cgd_norm, self.delta_FE) < self.convergence_thresh_cFE) or self.mf_ops_converged():\n",
    "            self.converged = True\n",
    "        else:\n",
    "            self.converged = False\n",
    "        return\n",
    "\n",
    "    def set_fpmethod_convergence_params(self):\n",
    "        self.iterations = 0\n",
    "        self.corr_grad_max = 10000\n",
    "        self.converged = False\n",
    "        self.terminate = False\n",
    "        self.large_gradient_counter = 0\n",
    "        return\n",
    "\n",
    "    def fixed_point_method(self):\n",
    "        for self.iterations in range(self.itermax):\n",
    "            self.diagH()\n",
    "            self.get_correlation_tensors()\n",
    "            self.get_FE()\n",
    "            self.update_outputdata()\n",
    "            self.check_convergence()\n",
    "            if self.iterations > self.itermin and (self.converged or self.terminate):\n",
    "                return self.converged, self.terminate\n",
    "        return False, False\n",
    "\n",
    "    def prt_outputdata(self):\n",
    "        for key in self.basic_params:\n",
    "            v = self.outputdata[key]\n",
    "            self.permaprt('%s ' %key, 0 if v<self.convergence_thresh_mfops else v)\n",
    "        return\n",
    "\n",
    "    def prt_postrun_data(self,verbose=True):\n",
    "        if verbose:\n",
    "            self.permaprt('Run concluded.\\nFinal number of iterations: %d out of %d.' %(self.iterations,self.itermax))\n",
    "            self.permaprt('Correlation gradient: %.0e' %np.linalg.norm(self.corr_grad_max))\n",
    "            self.permaprt('Free energy gradient: %.0e' %self.delta_FE)\n",
    "            self.permaprt('Ratio two largest order parameters: %.0e' %self.mf_ops_gap)\n",
    "            self.prt_outputdata()\n",
    "            self.permaprt('')\n",
    "        return\n",
    "\n",
    "    def intBZ(self, integrand):\n",
    "        if len(integrand.shape) == 1:\n",
    "            tup = (0)\n",
    "        else:\n",
    "            tup = (0,1)\n",
    "        return np.real_if_close( np.sum(integrand, axis=tup) / np.prod(self.kgridsize) )\n",
    "\n",
    "    def get_vars(self):\n",
    "        nB = self.nBands # number of particles in the cell : 4/8\n",
    "        h = int(nB/2)\n",
    "        N = int(factorial(nB)/factorial(h)**2) # combinations w/o repetitions : 6/70\n",
    "        neighood = len(self.square_distances) # number of square distances considered : 3/4\n",
    "        Bv = self.d # Bravais vectors\n",
    "        xy = self.d # spatial coordinates\n",
    "        pair = 2 # number of elements in a pair (of unit cells)\n",
    "        cp = 5 # cells paired\n",
    "        nkx, nky = self.kgridsize\n",
    "        return xy,nB,h,N,neighood,pair,Bv,cp,nkx,nky\n",
    "\n",
    "    def get_corr_cosq(self):\n",
    "        self.corr = self.corrhc*self.distance_mask\n",
    "        self.cosq = np.multiply(self.corr, np.conj(self.corr))\n",
    "        self.cosqhc = np.multiply(self.corrhc, np.conj(self.corrhc))\n",
    "        return\n",
    "\n",
    "    def get_correlation_tensors(self):\n",
    "        # Cd, C, bd, b : C/b are cell-/Bogoliubov-operators.\n",
    "        xy,nB,h,N,nhood,pair,Bv,cp,nkx,nky = self.get_vars()\n",
    "\n",
    "        U = np.conj(self.Uk) # [nkx, nky, Cd, bd]\n",
    "\n",
    "        beta = self.beta\n",
    "        energies_fermi = np.copy(self.Ek)\n",
    "        [a,b] = [np.amin(energies_fermi), np.amax(energies_fermi)]\n",
    "        def numbern(mu_, nn_, beta_, energies_):\n",
    "            e_aux = np.copy(energies_)\n",
    "            e_aux[beta_ * (e_aux - mu_) > 30] = 30 / beta_ + mu_\n",
    "            ferm = 1 / (np.exp(beta_ * (e_aux - mu_)) + 1)\n",
    "            return np.sum(ferm) - nn_\n",
    "        nn = self.band_filling*np.prod(self.kgridsize)\n",
    "        self.mu = brentq(numbern, a, b, args=(nn, beta, energies_fermi))\n",
    "        energies_fermi[beta*(energies_fermi - self.mu) > 30] = 30./beta + self.mu\n",
    "        fermi_distribution = 1. / (np.exp(beta * (energies_fermi - self.mu)) + 1)\n",
    "        fermi_distribution = self.repeat(fermi_distribution, nB).transpose(0,1,3,2)\n",
    "\n",
    "        U *= np.sqrt(fermi_distribution[:,:,:,:])\n",
    "        U = self.repeat(U, nB, nB) # [nkx, nky, Cd, bd, rep, rep]\n",
    "        Ud = np.conj(U.transpose(0,1,4,5,2,3)) # [nkx, nky, rep, rep, C, b]\n",
    "        UUd = np.multiply(U,Ud) # [nkx, nky, Cd, bd, C, b]\n",
    "        UUd = np.trace(UUd, axis1=3, axis2=5) # [nkx, nky, Cd, C]\n",
    "\n",
    "        newcorrhc = np.zeros([nhood,cp,nB,nB], dtype=np.complex128)\n",
    "        for _ in range(nhood):\n",
    "            newcorrhc[_] = self.intBZ(UUd[:,:,nax,:,:,]*self.eikdhc[_])\n",
    "        self.oldcorrhc = np.copy(self.corrhc)\n",
    "        self.corrhc = newcorrhc\n",
    "        self.get_corr_cosq()\n",
    "        return\n",
    "\n",
    "    def calc_correlations(self):\n",
    "        n = self.nBands\n",
    "        m = int(n/2) # Half filling set here.\n",
    "        km = self.kw.shape[2]\n",
    "        U = self.repeat(self.Uk, n, n)\n",
    "        Ud = np.conj(U.transpose(0,1,4,5,2,3))\n",
    "        UUd = np.multiply(U,Ud)\n",
    "        corr = np.trace(UUd[:,:,:,:m,:,:m], axis1=3, axis2=5) \n",
    "        corr = self.repeat(corr, km)\n",
    "        kweights = self.kw.transpose(3,4,0,1,2) # (0,1,3,4,2)\n",
    "        corr = np.multiply(corr, kweights)\n",
    "        corr = self.intBZ(corr)\n",
    "        corr = np.divide(corr, np.atleast_3d(self.nb))\n",
    "        self.corr = corr\n",
    "        self.cosq = np.multiply(corr, np.conj(corr))\n",
    "        return\n",
    "\n",
    "    def repeat(self, array, *args):\n",
    "        shape = list(array.shape) + list(args)\n",
    "        return array.repeat(np.prod(args)).reshape(shape)\n",
    "\n",
    "\n",
    "    def diagH(self):\n",
    "        Nkx, Nky = self.kgridsize\n",
    "        self.oldEk = np.copy(self.Ek)\n",
    "        for ix in range(Nkx):\n",
    "            for jy in range(Nky):\n",
    "                self.BZindices = (ix, jy)\n",
    "                self.get_Hamiltonian()\n",
    "                w,v = np.linalg.eigh(self.H) # w[i] i-th e.value, v[:,i] i-th column e.vector\n",
    "                w,v = self.sort(w,v) # Sort the eigenvalues/vectors in increasing order of evalues.\n",
    "                self.Ek[ix,jy] = np.real_if_close(w)\n",
    "                self.Uk[ix,jy] = np.real_if_close(v)\n",
    "        return\n",
    "\n",
    "    def get_kgrid(self):\n",
    "        nkx, nky = self.kgridsize\n",
    "        k1 = self.k_prim_vecs[0]\n",
    "        k2 = self.k_prim_vecs[1]\n",
    "        ks1 = np.reshape( np.kron(k1,np.linspace(0,1,nkx,endpoint=False)), (2,-1))\n",
    "        ks2 = np.reshape( np.kron(k2,np.linspace(0,1,nky,endpoint=False)), (2,-1))\n",
    "        # Repeat to promote linear ks to 2-d grids\n",
    "        ks1 = ks1.repeat(nky).reshape(self.d,nkx,nky).transpose(1,2,0)\n",
    "        ks2 = ks2.repeat(nkx).reshape(self.d,nky,nkx).transpose(2,1,0)\n",
    "        # Sum the two to get_ kgrid\n",
    "        # kgrid: tensor with shape [nkx,nky,xy]\n",
    "        self.kgrid = ks1 + ks2\n",
    "        return\n",
    "\n",
    "    def update_outputdata(self):\n",
    "        for key in self.outputdata.keys():\n",
    "            self.oldoutputdata[key] = self.outputdata[key]\n",
    "        self.get_outputdata()\n",
    "        return\n",
    "\n",
    "    def get_FE(self):\n",
    "        Hc = self.get_Hc()\n",
    "        bint = ric(np.sum(self.intBZ(self.Ek[:,:,:self.band_filling])))\n",
    "        self.oldFE = copy(self.FE)\n",
    "        self.FE = Hc + bint\n",
    "        return self.FE\n",
    "\n",
    "    def get_eikd(self):\n",
    "        # site_coos : [nB,xy] \n",
    "        # cellBravaisvecs : [Bv,xy]\n",
    "        xy,nB,h,N,neighood,pair,Bv,cp,nkx,nky = self.get_vars()\n",
    "        cpc = np.array([[[0,0],[0,0],[0,0],[0,0],[0,0]], [[0,0],[0,1],[1,1],[1,0],[1,-1]]]) # [pair,cp,Bv]\n",
    "        pair_coos = np.tensordot(cpc, self.cellBravaisvecs, axes=(2,0)) # [pair,cp,xy]\n",
    "        site_coos = self.repeat(self.site_coos, nB, cp, pair).transpose(3,0,2,1,4) # [cp,nB,nB,xy,pair]\n",
    "        site_coos[:,:,:,:,1] = site_coos[:,:,:,:,1].transpose(0,2,1,3)\n",
    "        cell_pair_coos = self.repeat(pair_coos, nB, nB).transpose(1,3,4,2,0) # [cp,nB,nB,xy,pair]\n",
    "        pair_distance = np.squeeze(np.diff(site_coos + cell_pair_coos, axis=4)) # [cp,nB,nB,xy] check this\n",
    "        distance_mat = np.sum(pair_distance**2, axis=3) # [cp,nB,nB]\n",
    "\n",
    "        distance_mask = np.zeros([neighood,cp,nB,nB], dtype=int) # [neighood,cp,nB,nB]\n",
    "        for _ in range(neighood):\n",
    "            distance_mask[_][np.where(distance_mat==self.square_distances[_])] = 1\n",
    "        distance_mask[:,0] *= np.triu(np.ones([nB,nB],dtype=int))[nax,:,:] # not ancillary, cures off-diag on cell-0\n",
    "\n",
    "        # distance_mask : [neighood,cp,nB,nB]\n",
    "        # distance_weight_flat : [neighood,nB,nB]\n",
    "        # distance_mask_flat : [neighood,nB,nB]\n",
    "        def foo(mat):\n",
    "            mat[mat!=0] = 1\n",
    "            return mat\n",
    "        def foo2(mat):\n",
    "            sh = mat.shape\n",
    "            m = np.zeros(sh, dtype=int)\n",
    "            m[:,:] = np.eye(sh[-1])\n",
    "            return 1-m\n",
    "\n",
    "        # *** triangular masks\n",
    "        self.distance_mask = np.copy(distance_mask)\n",
    "        self.distance_weight_flat = np.sum(self.distance_mask, axis=1)\n",
    "        self.distance_mask_flat = foo(np.copy(self.distance_weight_flat))\n",
    "        # *** Hermitian conjugate masks\n",
    "        self.distance_mask_hc = distance_mask + distance_mask.transpose(0,1,3,2)*foo2(distance_mask)\n",
    "        self.distance_weight_hc_flat = np.sum( self.distance_mask_hc, axis=1)\n",
    "        self.distance_mask_hc_flat = foo( np.copy( self.distance_weight_hc_flat))\n",
    "\n",
    "        # eikd : [neighood,nkx,nky,cp,nB,nB]\n",
    "        kd = np.tensordot(self.kgrid, pair_distance, axes=(2,3)) # [nkx,nky,cp,nB,nB]\n",
    "        eikd = np.exp(-1.j*kd)\n",
    "        self.eikd = np.zeros([neighood,nkx,nky,cp,nB,nB], dtype=np.complex128) # [neighood,nkx,nky,cp,nB,nB]\n",
    "        for _ in range(neighood):\n",
    "            self.eikd[_] = eikd*distance_mask[_,nax,nax,:,:,:]\n",
    "        self.eikdhc = self.eikd + np.conj(self.eikd.transpose(0,1,2,3,5,4))*foo2(self.eikd)\n",
    "        return\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74677b0",
   "metadata": {},
   "source": [
    "Class defining the checkerboard lattice model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481438e6",
   "metadata": {},
   "source": [
    "Methods\n",
    "----\n",
    "| Method | Description |\n",
    "|----|----|\n",
    "|`__init__` |  Initialize lattice related parameters  |\n",
    "|`fixed_point_method` |  Fixed-point search routine  |\n",
    "|`get_hamiltonian` |  Define the mean-field Hamiltonian, dependent on mean-field coefficients given by the correlation matrix  |\n",
    "|`diagH`|  Diagonalize the Hamiltonian for each $k$-vector in the Brilluoin zone. Obtain new k-space eigen-vectors and eigen-values (bands)  |\n",
    "|`get_correlation_tensors` |  Calculate correlation matrix  |\n",
    "|`get_FE`|  Calculate free energy  |\n",
    "|`check_convergence` |  Stop the fixed-point search i) after `itermax` iterations or ii) after `itermin` iterations and if iia) the largest mean-field parameter does not converge but oscillates between $\\pm n$ for `consecutive_oscillations` times, indicating a metallic phase (discard run) or iib) if both the free energy gradient and the correlation matrix gradient converged below `convergence_thresh_cFE` or the inverse ratios between the largest mean-field parameter and all others converged below `convergence_thresh_mfops`  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20705680",
   "metadata": {},
   "source": [
    "Attributes\n",
    "----\n",
    "| Attribute | type | Description |\n",
    "|----|-----|----|\n",
    "| `cellBravaisvecs` | int nparray | Bravais vectors of the unit cell |\n",
    "| `iterations` | int | Counts iterations |\n",
    "| `itermin` | int | Minimun number of iterations |\n",
    "| `itermax` | int | Maximun number of iterations |\n",
    "| `ncs` | int | Minimum number of neighboring cells (+1) needed to achieve full lattice tiling |\n",
    "| `nsites` | int | Number of lattice unit cell sites |\n",
    "| `site_coos` | int nparray | Sites coordinates in the lattice unit cell |\n",
    "| `Vsarray` | float nparray | Interaction amplitudes, `nV` terms including $V_0$ |\n",
    "| `xiQAH_loop_mask` | int nparray | Coordinates of the square plaquette over which $\\xi_{\\textrm{QAH}}$ is calculated |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d8cdd7",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# export\n",
    "class mean_field_analysis(checkerboard_eight_sites):\n",
    "    def __init__(self, itermin=20, itermax=700, kgridsize=10, Vgrid=5,\n",
    "                 beta=100, corrm='comp', rydberg=False):\n",
    "\n",
    "        # Number of interaction terms considered: nV=5 --> {V0, V1, V2, V3, V4}\n",
    "        self.nV = 5 \n",
    "\n",
    "        # Parameters.\n",
    "        self.rydberg = rydberg\n",
    "        self.kgridsize = [kgridsize, kgridsize] # Grating of the first Brilluoin zone\n",
    "        self.V1V2region = [2,6,0,4] # Region of V1-V2\n",
    "        self.Vsgridshape = [1,Vgrid,Vgrid,1,1] # Size of the grid in the region of {V1,V2}\n",
    "        ''' Run '''\n",
    "        self.itermin = itermin # Min number of fixed-point search iterations\n",
    "        self.itermax = itermax # Max number of fixed-point search iterations\n",
    "        self.beta = beta # Inverse temperature 1/kT\n",
    "        self.corrm = corrm\n",
    "        self.convergence_thresh_cFE = 1.E-12 # Threshold on correlation and FE for search convergence\n",
    "        self.convergence_thresh_mfops = 1.E-4 # Threshold on mf operators for search convergence\n",
    "        self.consecutive_oscillations = 200 # Consecutive Â±1 oscilattions of charge order parameter, signalling non-convergence (metallic phase)\n",
    "        self.oscillation_threshold = 1.E-4 # Threshold below which oscillation count starts\n",
    "        ''' Plot '''\n",
    "        self.dpi = 500\n",
    "        self.beta = 100 # Inverse temperature store1/kT\n",
    "        self.format = 'png'\n",
    "        self.datadir = 'data'\n",
    "\n",
    "        # Create data and figures directories.\n",
    "        self.datadir = 'data'\n",
    "        self.figuresdir = 'figures'\n",
    "        if not path.exists('./'+self.datadir): makedirs('./'+self.datadir)\n",
    "        if not path.exists('./'+self.figuresdir): makedirs('./'+self.figuresdir)\n",
    "\n",
    "        # These parameters must not change.\n",
    "        self.t = 1.0\n",
    "        self.J = 0.5\n",
    "\n",
    "        # Initialize some attributes.\n",
    "        self.markcol = ['#94cef3', '#6e92e8', '#cccccc', '#636363', '#fdbe85', '#3182bd', '#feedde', '#fb6a4a']\n",
    "        self.edgecol = ['#4799d1', '#193b78', '#a3a3a3', '#4f4f4f', '#fc9639', '#276897', '#fc9639', '#b5211b']\n",
    "        self.FE = 5\n",
    "        self.delta_FE = 5\n",
    "\n",
    "        # After all relevant parameteres have been defined, initialize the parent class.\n",
    "        checkerboard_eight_sites.__init__(self)\n",
    "        return\n",
    "\n",
    "    def get_empty_Vsdict(self):\n",
    "        Vsdict = {}\n",
    "        for _ in range(self.nV):\n",
    "            Vsdict[_] = 0\n",
    "        return Vsdict\n",
    "\n",
    "    def get_pool(self,rydberg=False,fullryd=True):\n",
    "        Vsarray_pool, Vsarray_pool_ryd, compact_Vsarray_pool_ryd = self.get_Vsarray_pool()\n",
    "        if rydberg:\n",
    "            if fullryd:\n",
    "                return Vsarray_pool_ryd\n",
    "            else:\n",
    "                return compact_Vsarray_pool_ryd \n",
    "        else:\n",
    "            return Vsarray_pool\n",
    "\n",
    "    def update_Vsarray(self,Vsarray,kwargs):\n",
    "        self.Vsarray = np.zeros(self.nV)\n",
    "        if 'V1' and 'V2' in kwargs.keys():\n",
    "            self.Vsarray[1:3] = [kwargs['V1'],kwargs['V2']]\n",
    "        else:\n",
    "            if len(Vsarray) == 2:\n",
    "                self.Vsarray[1:3] = Vsarray\n",
    "            else:\n",
    "                self.Vsarray[:len(Vsarray)] = Vsarray\n",
    "        return\n",
    "\n",
    "    def prepare_run(self, Vsarray=[0,3,3], verbose=True, rydberg=False, **kwargs):\n",
    "        self.update_Vsarray(Vsarray, kwargs)\n",
    "        self.init_EkUk()\n",
    "        self.get_hopping_matrix()\n",
    "        self.get_interaction_matrix()\n",
    "        self.init_outputdata()\n",
    "        self.permaprt('Running ' + ''.join(['V%s=%.2f, ' %(num,arg) for num,arg in enumerate(self.Vsarray)])[:-2], verbose=verbose)\n",
    "        self.init_rnd_corr(verbose)\n",
    "        self.set_fpmethod_convergence_params()\n",
    "        return\n",
    "\n",
    "    def prepare_grid_run(self, V3=0, verbose=False, Vgrid=4, V1V2region=[2,6,0,4], rydberg=False):\n",
    "        # Get pool of Vsarray.\n",
    "        self.V1V2region = V1V2region # Region of V1-V2\n",
    "        self.Vsgridshape = [1,Vgrid,Vgrid,1,1] # Size of the grid in the region of {V1,V2}\n",
    "        self.Vsdict = self.get_empty_Vsdict()\n",
    "        self.Vsdict[1], self.Vsdict[2] = self.get_V1V2s()\n",
    "        self.Vsdict[3] = V3\n",
    "        self.init_datadict()\n",
    "        return\n",
    "\n",
    "    def single_run(self, Vsarray=[0,3,3], verbose=True, rydberg=False, **kwargs):\n",
    "            self.prepare_run(Vsarray=Vsarray, verbose=verbose, rydberg=rydberg, **kwargs)\n",
    "            V1,V2 = self.Vsarray[1],self.Vsarray[2]\n",
    "            if not (rydberg and (V2>=V1 or V1>=8*V2)):\n",
    "                self.fixed_point_method()\n",
    "                self.prt_postrun_data(verbose)\n",
    "            return\n",
    "\n",
    "    def sanity_check(self,rydberg=False):\n",
    "        V1,V2 = self.Vsarray[1],self.Vsarray[2]\n",
    "        if not (rydberg and (V2>=V1 or V1>=8*V2)):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def grid_run(self, V3=0, verbose=False, Vgrid=4, V1V2region=[2,6,0,4], rydberg=False):\n",
    "        self.prepare_grid_run(V3=V3, verbose=verbose, Vgrid=Vgrid, V1V2region=V1V2region, rydberg=rydberg)\n",
    "        Vsarray_pool = self.get_pool(rydberg=rydberg)\n",
    "        counter = 0\n",
    "        for Vsarray in Vsarray_pool:\n",
    "            self.prepare_run(rydberg=rydberg, Vsarray=Vsarray, verbose=verbose)\n",
    "            if self.sanity_check(rydberg=rydberg):\n",
    "                self.fixed_point_method()\n",
    "                self.prt_postrun_data(verbose)\n",
    "            self.store_grid_data(counter)\t\n",
    "            counter += 1\n",
    "        return\n",
    "\n",
    "    def store_grid_data(self,counter):\n",
    "        V2 = self.Vsgridshape[1]\n",
    "        i,j = counter//V2, counter%V2\n",
    "        self.datadict['Ek'][0,i,j] = self.Ek\n",
    "        self.datadict['FE'][0,i,j] = self.FE\n",
    "        self.datadict['xiQAH'][0,i,j] = self.outputdata['xiQAH']\n",
    "        self.datadict['corrhc'][0,i,j] = self.corrhc \n",
    "        for _ in range(self.nV):\n",
    "            self.datadict['rho%d'%_][0,i,j] = self.outputdata['rho%d'%_]\n",
    "        return\n",
    "\n",
    "    def init_datadict(self):\n",
    "        Vgs = self.Vsgridshape\n",
    "        def scal(): return np.zeros( self.Vsgridshape, dtype=float)\n",
    "        def Ek(): return np.zeros(Vgs + self.kgridsize + [self.nsites], dtype=float)\n",
    "        def crhc(): return np.zeros( self.Vsgridshape + [self.nV, self.ncs, self.nsites, self.nsites], dtype=complex)\n",
    "        self.datadict = {\n",
    "            'Ek' : Ek(),\n",
    "            'FE' : scal(),\n",
    "            'xiQAH' : scal(),\n",
    "            'corrhc' : crhc(),\n",
    "        }\n",
    "        for _ in range(self.nV):\n",
    "            self.datadict['rho%d'%_] = scal()\n",
    "        return\n",
    "\n",
    "    def get_V1V2_mat(self):\n",
    "        N1, N2 = self.Vsgridshape[1], self.Vsgridshape[2]\n",
    "        V1, V2 = self.Vsdict[1], self.Vsdict[2]\n",
    "        V1 = np.repeat(V1, N2).reshape(N1,N2)\n",
    "        V2 = np.repeat(V2, N1).reshape(N2,N1).T\n",
    "        return V1, V2\n",
    "\n",
    "    def get_vals(self,v,t=0,V1=None,V2=None):\n",
    "        if V1 is None:\n",
    "            V1, V2 = self.get_V1V2_mat()\n",
    "        coo = np.where(v > t)\n",
    "        x = V1[coo].flatten()\n",
    "        y = V2[coo].flatten()\n",
    "        c = v[coo].flatten()\n",
    "        return x,y,c\n",
    "\n",
    "    def get_V1V2_conditioned_V3(self,param):\n",
    "        r = self.get_plot_pool('compryd')\n",
    "        gap = .02\n",
    "        coo = np.where((param+gap > r) & (r > param-gap))\n",
    "        x = r[:,0][coo]\n",
    "        y = r[:,1][coo]\n",
    "        return x,y\n",
    "\n",
    "    def mf_ops_converged(self):\n",
    "        mf_ops = np.array([self.outputdata['xiQAH']] + [self.outputdata['rho%d'%_] for _ in range(1,4)])\n",
    "        mf_ops /= np.max(mf_ops)\n",
    "        mf_ops[mf_ops==1.] = 0\n",
    "        self.mf_ops_gap = np.max(mf_ops)\n",
    "        mf_ops[mf_ops < self.convergence_thresh_mfops] = 0\n",
    "        mf_ops_converged = not bool(np.sum(mf_ops))\n",
    "        return mf_ops_converged\n",
    "\n",
    "    def get_mf_ops(self, show_warnings=True):\n",
    "        # Extract data for phase diagram plot.\n",
    "        xiQAH = np.abs(self.datadict['xiQAH'].squeeze())\n",
    "        V1V2gridshape = xiQAH.shape\n",
    "        # mf_ops : tensor of order parameters.\n",
    "        mf_ops = np.zeros((4,) + V1V2gridshape)\n",
    "        mf_ops[0] = xiQAH\n",
    "        for _ in range(1, 4):\n",
    "            mf_ops[_] = self.datadict['rho'+str(_)].squeeze()\n",
    "        # Set mf_ops to zero when below numeric threshold.\n",
    "        mf_ops[mf_ops < self.convergence_thresh_mfops] = 0\n",
    "        # Check if there is more than one mf_ops above threshold. It should not be the case. Print a warning.\n",
    "        ms = np.sum(np.array(mf_ops, dtype=bool), axis=0)\n",
    "        ms[ms==1] = 0\n",
    "        cond = np.array_equal(ms, np.zeros(V1V2gridshape))\n",
    "        if not cond:\n",
    "            # Identify V1,V2 with multiple finitprinte op, set them all to 0 (invalidate data point).\n",
    "            xs,ys = np.where(ms != 0)\n",
    "            V1,V2 = self.get_V1V2_mat()\n",
    "            self.permaprt('*'*300+'Beware! Data point with multiple finite order parameters!',verbose=show_warnings)\n",
    "            for _ in range(len(xs)):\n",
    "                x,y = xs[_],ys[_]\n",
    "                self.permaprt('V1: %.2f, V2: %.2f, ' %(V1[x,y], V2[x,y]), mf_ops[:,x,y], verbose=show_warnings)\n",
    "                mf_ops[:,x,y] *= 0\n",
    "        return mf_ops\n",
    "\n",
    "    def get_pd_ordparams(self,ax,markersize,show_warnings=True):\n",
    "        mf_ops = self.get_mf_ops(show_warnings=show_warnings)\n",
    "        if self.rydberg:\n",
    "            for iV1 in range(len(self.V1s)):\n",
    "                w = np.where(self.V2s > 511/574*self.V1s[iV1])\n",
    "                mf_ops[:, iV1, w] *= 0\n",
    "            mf_ops[:, :, np.where(self.V2s == 0)] *= 0\n",
    "        # Draw scatter\n",
    "        colors = ['Reds', 'Greens_r', 'Blues_r', 'spring']\n",
    "        scs = []\n",
    "        for _ in range(4):\n",
    "            x, y, c = self.get_vals(mf_ops[_])\n",
    "            sc = ax.scatter(x, y, c=c, cmap=colors[_], s=markersize, marker='s')\n",
    "            scs.append(sc)\n",
    "        return scs[0], ax\n",
    "\n",
    "    def plot_phasediag_rydberg(self, markersize=60, figsize=4.5, fontsize=15):\n",
    "        plt.close()\n",
    "\n",
    "        # Define figure structure\n",
    "        aspect_ratio = 1.2\n",
    "        fig = plt.figure(figsize=[figsize*aspect_ratio,figsize])\n",
    "        gs0 = mpl.gridspec.GridSpec(1,2, width_ratios=[100,10])\n",
    "        ax1 = fig.add_subplot(gs0[0,0])\n",
    "        ax2 = fig.add_subplot(gs0[0,1])\n",
    "\n",
    "        # Params\n",
    "        tickspad = 3\n",
    "        cbarpad = 1\n",
    "        spinelw = 1\n",
    "        lw = 1\n",
    "\n",
    "        # Order parameter scatter plot\n",
    "        sc, ax1 = self.get_pd_ordparams(ax1,markersize,show_warnings=False)\n",
    "\n",
    "        # Axes limits\n",
    "        x0,x1,y0,y1 = self.V1V2region\n",
    "        ax1.set_xlim(x0, x1)\n",
    "        ax1.set_ylim(y0, y1)\n",
    "\n",
    "        # Set ticks\n",
    "        ax1.set_xticks(np.linspace(x0,x1,1+x1-x0))\n",
    "        ax1.set_yticks(np.linspace(y0,y1,1+y1-y0))\n",
    "\n",
    "        # Set tick labels\n",
    "        ax1.set_xticklabels(np.linspace(x0,x1,1+x1-x0), fontsize=fontsize)\n",
    "        ax1.set_yticklabels(np.linspace(y0,y1,1+y1-y0), fontsize=fontsize)\n",
    "\n",
    "        # Tick params\n",
    "        ax1.tick_params(axis=\"x\", pad=tickspad, labelsize=fontsize)\n",
    "        ax1.tick_params(axis=\"y\", pad=tickspad, labelsize=fontsize)\n",
    "\n",
    "        # Tick labels\n",
    "        ax1.set_xlabel(r'$V_1/t$', fontsize=fontsize)\n",
    "        ax1.set_ylabel(r'$V_2/t$', rotation=0, fontsize=fontsize)\n",
    "        ax1.yaxis.set_label_coords(-1./figsize*aspect_ratio, .58)\n",
    "\n",
    "        # Set spines\n",
    "        for axis in ['top','bottom','left','right']:\n",
    "            ax1.spines[axis].set_linewidth(spinelw)\n",
    "\n",
    "        # Draw Rydberg potential boundaries\n",
    "        a = 10\n",
    "        ax1.plot([0, a], [0, a*511/574], '--', c='black', lw=lw)\n",
    "        ax1.plot([0, a], [0, a/8], '--', c='black', lw=lw)\n",
    "\n",
    "        # Colorbar\n",
    "        ticks = [.04, .06, .08, .10]\n",
    "        cbar = fig.colorbar(sc, ticks=ticks, cax=ax2, pad=cbarpad)\n",
    "        cbar.ax.tick_params(which='major', length=0, width=0, labelsize=fontsize, pad=1)\n",
    "        cbar.ax.set_title(r'$\\xi_{QAH}$', fontsize=fontsize)\n",
    "\n",
    "        # Finalize\n",
    "        ax1.set_aspect(1)\n",
    "        return plt\n",
    "\n",
    "    def plot_phasediag_fixedV3(self, V3=0, markersize=60, figsize=3, fontsize=15):\n",
    "        plt.close()\n",
    "\n",
    "        # Define figure structure\n",
    "        aspect_ratio = 1\n",
    "        fig = plt.figure(figsize=[figsize*aspect_ratio,figsize])\n",
    "        gs0 = mpl.gridspec.GridSpec(1,1)\n",
    "        ax1 = fig.add_subplot(gs0[0,0])\n",
    "        ax1.set_aspect(aspect_ratio)\n",
    "\n",
    "        # Params\n",
    "        tickspad = 3\n",
    "        spinelw = 1\n",
    "\n",
    "        # Order parameter scatter plot\n",
    "        sc, ax1 = self.get_pd_ordparams(ax1,markersize,show_warnings=True)\n",
    "\n",
    "        # Axes limits\n",
    "        x0,x1,y0,y1 = self.V1V2region\n",
    "        ax1.set_xlim(x0, x1)\n",
    "        ax1.set_ylim(y0, y1)\n",
    "\n",
    "        # Set ticks\n",
    "        ax1.set_xticks(np.linspace(x0,x1,1+x1-x0))\n",
    "        ax1.set_yticks(np.linspace(y0,y1,1+y1-y0))\n",
    "\n",
    "        # Set tick labels\n",
    "        ax1.set_xticklabels(np.linspace(x0,x1,1+x1-x0), fontsize=fontsize)\n",
    "        ax1.set_yticklabels(np.linspace(y0,y1,1+y1-y0), fontsize=fontsize)\n",
    "\n",
    "        # Tick params\n",
    "        ax1.tick_params(axis=\"x\", pad=tickspad, labelsize=fontsize)\n",
    "        ax1.tick_params(axis=\"y\", pad=tickspad, labelsize=fontsize)\n",
    "\n",
    "        # Axes labels\n",
    "        ax1.set_xlabel(r'$V_1/t$', fontsize=fontsize)\n",
    "        ax1.set_ylabel(r'$V_2/t$', rotation=0 , fontsize=fontsize)\n",
    "        ax1.yaxis.set_label_coords(-1./figsize*aspect_ratio, .58)\n",
    "\n",
    "        # Set spines\n",
    "        for axis in ['top','bottom','left','right']:\n",
    "            ax1.spines[axis].set_linewidth(spinelw)\n",
    "        return plt\n",
    "\n",
    "    def get_Vsarray_pool(self):\n",
    "        # Full V3 fixed\n",
    "        dim = np.prod(self.Vsgridshape)\n",
    "        Vsarray_pool = np.zeros([dim,self.nV], dtype=float)\n",
    "        for _ in range(self.nV):\n",
    "            nr = int(np.prod(self.Vsgridshape[_+1:]))\n",
    "            nt = int(np.prod(self.Vsgridshape[:_]))\n",
    "            Vsarray_pool[:,_] = np.tile(np.repeat(self.Vsdict[_],nr),nt)\n",
    "\n",
    "        # Full pool, Rydberg potential\n",
    "        def nan(v): v[v==0]=np.nan; return v\n",
    "        r = np.copy(Vsarray_pool)\n",
    "        V1 = r[:,1]\n",
    "        V2 = r[:,2]\n",
    "        r[:,3] = V1*V2 / (9*V1 - 8*V2)\n",
    "        r[:,4] = 7*V1*V2 / (124*V1 - 117*V2)\n",
    "        r, indexes = np.unique(r,axis=0,return_index=True)\n",
    "        Vsarray_pool_ryd = np.zeros(r.shape)\n",
    "        Vsarray_pool_ryd[indexes] = r\n",
    "\n",
    "        # Compact pool, Rydberg potential\n",
    "        r = np.copy(Vsarray_pool_ryd)\n",
    "        for _ in range(1,self.nV):\n",
    "            cond = np.where(r[:,_] == 0); rp = np.delete(r, cond, 0)\n",
    "            cond = np.isnan(r[:,_]);      r = np.delete(r, cond, 0)\n",
    "        cond = np.where(r[:,2] >= r[:,1]);   r = np.delete(r, cond, 0)\n",
    "        cond = np.where(r[:,1] >= 8*r[:,2]); r = np.delete(r, cond, 0)\n",
    "        compact_Vsarray_pool_ryd = r\n",
    "        return Vsarray_pool, Vsarray_pool_ryd, compact_Vsarray_pool_ryd \n",
    "\n",
    "    def get_V1V2s(self):\n",
    "        V1s = np.linspace(self.V1V2region[0], self.V1V2region[1], self.Vsgridshape[1])\n",
    "        V2s = np.linspace(self.V1V2region[2], self.V1V2region[3], self.Vsgridshape[2])\n",
    "        return V1s, V2s\n",
    "\n",
    "    def permaprt(self,*message,verbose=True):\n",
    "        # Pr*nt function with a weird enough name, to make it easy to find \"pr*nt()\" statements dropped around.\n",
    "        if verbose: print(*message)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5da7afb",
   "metadata": {},
   "source": [
    "Perform the mean-field analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e691687b",
   "metadata": {},
   "source": [
    "Methods\n",
    "----\n",
    "| Method  | Description |\n",
    "|----|----|\n",
    "|`__init__` |  Initialize Hamiltonian related parameters, then call checkerboard_eight_sites.__init__()  |\n",
    "|`prepare_run`|  Update the set of $V_i$, define Hamiltonian accordingly, initialize random correlation matrix, set and initialize other run parameters like k-space eigen-vectors and eigen-values (bands)  |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
